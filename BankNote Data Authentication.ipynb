{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c2d1d4f",
   "metadata": {},
   "source": [
    "# BankNote Data Authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "496dec4d",
   "metadata": {},
   "source": [
    "Date: 2/9/22"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "739a21e7",
   "metadata": {},
   "source": [
    "Max Rivera"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ceb6afb1",
   "metadata": {},
   "source": [
    "Dataset from https://archive.ics.uci.edu/ml/datasets/banknote+authentication"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9140a92a",
   "metadata": {},
   "source": [
    "Data includes features extracted from images of banknotes, with classes indicating either fraudulent or authentic. I build a shallow neural network to predict the class of each banknote. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e92d3fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5913718",
   "metadata": {},
   "source": [
    "### Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6756ca5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0         1        2        3  4\n",
       "0     3.62160   8.66610  -2.8073 -0.44699  0\n",
       "1     4.54590   8.16740  -2.4586 -1.46210  0\n",
       "2     3.86600  -2.63830   1.9242  0.10645  0\n",
       "3     3.45660   9.52280  -4.0112 -3.59440  0\n",
       "4     0.32924  -4.45520   4.5718 -0.98880  0\n",
       "...       ...       ...      ...      ... ..\n",
       "1367  0.40614   1.34920  -1.4501 -0.55949  1\n",
       "1368 -1.38870  -4.87730   6.4774  0.34179  1\n",
       "1369 -3.75030 -13.45860  17.5932 -2.77710  1\n",
       "1370 -3.56370  -8.38270  12.3930 -1.28230  1\n",
       "1371 -2.54190  -0.65804   2.6842  1.19520  1\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data_banknote_authentication.txt',header=None) \n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bb8821",
   "metadata": {},
   "source": [
    "Our csv file does not have headers for features, so we need to add them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90840af1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness  curtosis  entropy  class\n",
       "0      3.62160   8.66610   -2.8073 -0.44699      0\n",
       "1      4.54590   8.16740   -2.4586 -1.46210      0\n",
       "2      3.86600  -2.63830    1.9242  0.10645      0\n",
       "3      3.45660   9.52280   -4.0112 -3.59440      0\n",
       "4      0.32924  -4.45520    4.5718 -0.98880      0\n",
       "...        ...       ...       ...      ...    ...\n",
       "1367   0.40614   1.34920   -1.4501 -0.55949      1\n",
       "1368  -1.38870  -4.87730    6.4774  0.34179      1\n",
       "1369  -3.75030 -13.45860   17.5932 -2.77710      1\n",
       "1370  -3.56370  -8.38270   12.3930 -1.28230      1\n",
       "1371  -2.54190  -0.65804    2.6842  1.19520      1\n",
       "\n",
       "[1372 rows x 5 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns = ['variance','skewness','curtosis','entropy','class']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9da83f9",
   "metadata": {},
   "source": [
    "### Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "6f0c1a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='class', ylabel='count'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# look at how balanced classes are\n",
    "sns.countplot(x='class', data=df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1b95f5a",
   "metadata": {},
   "source": [
    "The data is balanced enough to use metrics like accuracy. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "20939eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# correlation of features to class\n",
    "df.corr()['class'].sort_values().plot(kind='bar')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3bc234c",
   "metadata": {},
   "source": [
    "Some of the features aren't highly correlated with the output, but I don't know exactly how\n",
    "they'll be used inside a non-linear model, so I keep them. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a5e4b25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# correlation of features with eachother\n",
    "sns.heatmap(df.corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5a0ff2e",
   "metadata": {},
   "source": [
    "A heatmap shows how features correlated with eachother. Entropy, which has a pretty low correlation with the \n",
    "the output (around 0), has slightly higher correlation with other features. This could be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "48ea97ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "variance    0\n",
       "skewness    0\n",
       "curtosis    0\n",
       "entropy     0\n",
       "class       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check if there are any null values in each column\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31c9cab3",
   "metadata": {},
   "source": [
    "Fortunately the dataset does not contain any missing data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbbc731f",
   "metadata": {},
   "source": [
    "### Train Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b9327add",
   "metadata": {},
   "outputs": [],
   "source": [
    "# separate data from labels \n",
    "X = df.drop('class',axis=1)\n",
    "y = df['class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7b9cae73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>variance</th>\n",
       "      <th>skewness</th>\n",
       "      <th>curtosis</th>\n",
       "      <th>entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3.62160</td>\n",
       "      <td>8.66610</td>\n",
       "      <td>-2.8073</td>\n",
       "      <td>-0.44699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.54590</td>\n",
       "      <td>8.16740</td>\n",
       "      <td>-2.4586</td>\n",
       "      <td>-1.46210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.86600</td>\n",
       "      <td>-2.63830</td>\n",
       "      <td>1.9242</td>\n",
       "      <td>0.10645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.45660</td>\n",
       "      <td>9.52280</td>\n",
       "      <td>-4.0112</td>\n",
       "      <td>-3.59440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.32924</td>\n",
       "      <td>-4.45520</td>\n",
       "      <td>4.5718</td>\n",
       "      <td>-0.98880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1367</th>\n",
       "      <td>0.40614</td>\n",
       "      <td>1.34920</td>\n",
       "      <td>-1.4501</td>\n",
       "      <td>-0.55949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1368</th>\n",
       "      <td>-1.38870</td>\n",
       "      <td>-4.87730</td>\n",
       "      <td>6.4774</td>\n",
       "      <td>0.34179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>-3.75030</td>\n",
       "      <td>-13.45860</td>\n",
       "      <td>17.5932</td>\n",
       "      <td>-2.77710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1370</th>\n",
       "      <td>-3.56370</td>\n",
       "      <td>-8.38270</td>\n",
       "      <td>12.3930</td>\n",
       "      <td>-1.28230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1371</th>\n",
       "      <td>-2.54190</td>\n",
       "      <td>-0.65804</td>\n",
       "      <td>2.6842</td>\n",
       "      <td>1.19520</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1372 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      variance  skewness  curtosis  entropy\n",
       "0      3.62160   8.66610   -2.8073 -0.44699\n",
       "1      4.54590   8.16740   -2.4586 -1.46210\n",
       "2      3.86600  -2.63830    1.9242  0.10645\n",
       "3      3.45660   9.52280   -4.0112 -3.59440\n",
       "4      0.32924  -4.45520    4.5718 -0.98880\n",
       "...        ...       ...       ...      ...\n",
       "1367   0.40614   1.34920   -1.4501 -0.55949\n",
       "1368  -1.38870  -4.87730    6.4774  0.34179\n",
       "1369  -3.75030 -13.45860   17.5932 -2.77710\n",
       "1370  -3.56370  -8.38270   12.3930 -1.28230\n",
       "1371  -2.54190  -0.65804    2.6842  1.19520\n",
       "\n",
       "[1372 rows x 4 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0b866603",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0\n",
       "1       0\n",
       "2       0\n",
       "3       0\n",
       "4       0\n",
       "       ..\n",
       "1367    1\n",
       "1368    1\n",
       "1369    1\n",
       "1370    1\n",
       "1371    1\n",
       "Name: class, Length: 1372, dtype: int64"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "f00877d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97f960c0",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "f0c29cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min-max scaling is a typical normalization technique used \n",
    "scaler = MinMaxScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "7936a07a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1029, 4)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4245edf",
   "metadata": {},
   "source": [
    "### Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "1ad81bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(4,activation='relu'))\n",
    "model.add(Dense(2,activation='relu'))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy',optimizer='adam')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6c9ad14",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "284c51da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train <class 'numpy.ndarray'>\n",
      "y_train <class 'numpy.ndarray'>\n",
      "X_test <class 'numpy.ndarray'>\n",
      "y_test <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# make sure inputs to model.fit are all numpy arrays \n",
    "print('X_train',type(X_train))\n",
    "print('y_train',type(y_train))\n",
    "print('X_test',type(X_test))\n",
    "print('y_test',type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d4395f08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y_train <class 'numpy.ndarray'>\n",
      "y_test <class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "y_train = np.array(y_train)\n",
    "print('y_train',type(y_train))\n",
    "y_test = np.array(y_test)\n",
    "print('y_test',type(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "cde68c43",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1029 samples, validate on 343 samples\n",
      "Epoch 1/600\n",
      "1029/1029 [==============================] - 1s 611us/sample - loss: 0.6738 - val_loss: 0.6638\n",
      "Epoch 2/600\n",
      "1029/1029 [==============================] - 0s 62us/sample - loss: 0.6582 - val_loss: 0.6455\n",
      "Epoch 3/600\n",
      "1029/1029 [==============================] - 0s 65us/sample - loss: 0.6435 - val_loss: 0.6313\n",
      "Epoch 4/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.6337 - val_loss: 0.6219\n",
      "Epoch 5/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.6267 - val_loss: 0.6146\n",
      "Epoch 6/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.6208 - val_loss: 0.6081\n",
      "Epoch 7/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.6149 - val_loss: 0.6027\n",
      "Epoch 8/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.6093 - val_loss: 0.5967\n",
      "Epoch 9/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.6035 - val_loss: 0.5905\n",
      "Epoch 10/600\n",
      "1029/1029 [==============================] - 0s 70us/sample - loss: 0.5975 - val_loss: 0.5850\n",
      "Epoch 11/600\n",
      "1029/1029 [==============================] - 0s 66us/sample - loss: 0.5913 - val_loss: 0.5787\n",
      "Epoch 12/600\n",
      "1029/1029 [==============================] - 0s 69us/sample - loss: 0.5851 - val_loss: 0.5727\n",
      "Epoch 13/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.5787 - val_loss: 0.5660\n",
      "Epoch 14/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.5724 - val_loss: 0.5607\n",
      "Epoch 15/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.5657 - val_loss: 0.5540\n",
      "Epoch 16/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.5591 - val_loss: 0.5473\n",
      "Epoch 17/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.5527 - val_loss: 0.5402\n",
      "Epoch 18/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.5454 - val_loss: 0.5343\n",
      "Epoch 19/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.5385 - val_loss: 0.5278\n",
      "Epoch 20/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.5316 - val_loss: 0.5209\n",
      "Epoch 21/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.5247 - val_loss: 0.5141\n",
      "Epoch 22/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.5171 - val_loss: 0.5066\n",
      "Epoch 23/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.5096 - val_loss: 0.5008\n",
      "Epoch 24/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.5024 - val_loss: 0.4927\n",
      "Epoch 25/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.4952 - val_loss: 0.4859\n",
      "Epoch 26/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.4875 - val_loss: 0.4789\n",
      "Epoch 27/600\n",
      "1029/1029 [==============================] - 0s 64us/sample - loss: 0.4800 - val_loss: 0.4713\n",
      "Epoch 28/600\n",
      "1029/1029 [==============================] - 0s 62us/sample - loss: 0.4728 - val_loss: 0.4647\n",
      "Epoch 29/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.4657 - val_loss: 0.4576\n",
      "Epoch 30/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.4577 - val_loss: 0.4497\n",
      "Epoch 31/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.4500 - val_loss: 0.4433\n",
      "Epoch 32/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.4422 - val_loss: 0.4351\n",
      "Epoch 33/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.4329 - val_loss: 0.4256\n",
      "Epoch 34/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.4230 - val_loss: 0.4167\n",
      "Epoch 35/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.4133 - val_loss: 0.4080\n",
      "Epoch 36/600\n",
      "1029/1029 [==============================] - 0s 69us/sample - loss: 0.4037 - val_loss: 0.3982\n",
      "Epoch 37/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.3945 - val_loss: 0.3878\n",
      "Epoch 38/600\n",
      "1029/1029 [==============================] - 0s 70us/sample - loss: 0.3840 - val_loss: 0.3795\n",
      "Epoch 39/600\n",
      "1029/1029 [==============================] - 0s 64us/sample - loss: 0.3745 - val_loss: 0.3679\n",
      "Epoch 40/600\n",
      "1029/1029 [==============================] - 0s 67us/sample - loss: 0.3652 - val_loss: 0.3575\n",
      "Epoch 41/600\n",
      "1029/1029 [==============================] - 0s 65us/sample - loss: 0.3561 - val_loss: 0.3485\n",
      "Epoch 42/600\n",
      "1029/1029 [==============================] - 0s 66us/sample - loss: 0.3469 - val_loss: 0.3398\n",
      "Epoch 43/600\n",
      "1029/1029 [==============================] - 0s 63us/sample - loss: 0.3377 - val_loss: 0.3313\n",
      "Epoch 44/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.3291 - val_loss: 0.3216\n",
      "Epoch 45/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.3202 - val_loss: 0.3129\n",
      "Epoch 46/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.3125 - val_loss: 0.3045\n",
      "Epoch 47/600\n",
      "1029/1029 [==============================] - 0s 64us/sample - loss: 0.3040 - val_loss: 0.2969\n",
      "Epoch 48/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.2965 - val_loss: 0.2909\n",
      "Epoch 49/600\n",
      "1029/1029 [==============================] - 0s 80us/sample - loss: 0.2898 - val_loss: 0.2821\n",
      "Epoch 50/600\n",
      "1029/1029 [==============================] - 0s 63us/sample - loss: 0.2819 - val_loss: 0.2738\n",
      "Epoch 51/600\n",
      "1029/1029 [==============================] - 0s 64us/sample - loss: 0.2752 - val_loss: 0.2664\n",
      "Epoch 52/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.2688 - val_loss: 0.2598\n",
      "Epoch 53/600\n",
      "1029/1029 [==============================] - 0s 64us/sample - loss: 0.2617 - val_loss: 0.2527\n",
      "Epoch 54/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.2557 - val_loss: 0.2472\n",
      "Epoch 55/600\n",
      "1029/1029 [==============================] - 0s 64us/sample - loss: 0.2503 - val_loss: 0.2409\n",
      "Epoch 56/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.2443 - val_loss: 0.2335\n",
      "Epoch 57/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.2387 - val_loss: 0.2297\n",
      "Epoch 58/600\n",
      "1029/1029 [==============================] - 0s 62us/sample - loss: 0.2328 - val_loss: 0.2228\n",
      "Epoch 59/600\n",
      "1029/1029 [==============================] - 0s 63us/sample - loss: 0.2276 - val_loss: 0.2182\n",
      "Epoch 60/600\n",
      "1029/1029 [==============================] - 0s 65us/sample - loss: 0.2227 - val_loss: 0.2143\n",
      "Epoch 61/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.2176 - val_loss: 0.2075\n",
      "Epoch 62/600\n",
      "1029/1029 [==============================] - 0s 63us/sample - loss: 0.2130 - val_loss: 0.2017\n",
      "Epoch 63/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.2085 - val_loss: 0.1989\n",
      "Epoch 64/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.2041 - val_loss: 0.1957\n",
      "Epoch 65/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.1993 - val_loss: 0.1891\n",
      "Epoch 66/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.1953 - val_loss: 0.1845\n",
      "Epoch 67/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.1917 - val_loss: 0.1815\n",
      "Epoch 68/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.1870 - val_loss: 0.1770\n",
      "Epoch 69/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.1829 - val_loss: 0.1725\n",
      "Epoch 70/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.1791 - val_loss: 0.1687\n",
      "Epoch 71/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.1758 - val_loss: 0.1643\n",
      "Epoch 72/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.1720 - val_loss: 0.1614\n",
      "Epoch 73/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.1685 - val_loss: 0.1600\n",
      "Epoch 74/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.1653 - val_loss: 0.1555\n",
      "Epoch 75/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.1618 - val_loss: 0.1526\n",
      "Epoch 76/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.1586 - val_loss: 0.1487\n",
      "Epoch 77/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.1555 - val_loss: 0.1475\n",
      "Epoch 78/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.1531 - val_loss: 0.1421\n",
      "Epoch 79/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.1499 - val_loss: 0.1402\n",
      "Epoch 80/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.1469 - val_loss: 0.1376\n",
      "Epoch 81/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.1440 - val_loss: 0.1338\n",
      "Epoch 82/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.1414 - val_loss: 0.1346\n",
      "Epoch 83/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.1395 - val_loss: 0.1292\n",
      "Epoch 84/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.1364 - val_loss: 0.1258\n",
      "Epoch 85/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.1346 - val_loss: 0.1258\n",
      "Epoch 86/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.1326 - val_loss: 0.1228\n",
      "Epoch 87/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.1296 - val_loss: 0.1219\n",
      "Epoch 88/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.1273 - val_loss: 0.1164\n",
      "Epoch 89/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.1251 - val_loss: 0.1161\n",
      "Epoch 90/600\n",
      "1029/1029 [==============================] - 0s 64us/sample - loss: 0.1234 - val_loss: 0.1126\n",
      "Epoch 91/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.1210 - val_loss: 0.1105\n",
      "Epoch 92/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.1191 - val_loss: 0.1111\n",
      "Epoch 93/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.1169 - val_loss: 0.1075\n",
      "Epoch 94/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.1149 - val_loss: 0.1056\n",
      "Epoch 95/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.1132 - val_loss: 0.1033\n",
      "Epoch 96/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.1113 - val_loss: 0.1018\n",
      "Epoch 97/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.1095 - val_loss: 0.0998\n",
      "Epoch 98/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.1078 - val_loss: 0.0980\n",
      "Epoch 99/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.1059 - val_loss: 0.0972\n",
      "Epoch 100/600\n",
      "1029/1029 [==============================] - 0s 67us/sample - loss: 0.1044 - val_loss: 0.0947\n",
      "Epoch 101/600\n",
      "1029/1029 [==============================] - 0s 71us/sample - loss: 0.1029 - val_loss: 0.0935\n",
      "Epoch 102/600\n",
      "1029/1029 [==============================] - 0s 69us/sample - loss: 0.1013 - val_loss: 0.0925\n",
      "Epoch 103/600\n",
      "1029/1029 [==============================] - 0s 64us/sample - loss: 0.1003 - val_loss: 0.0901\n",
      "Epoch 104/600\n",
      "1029/1029 [==============================] - 0s 62us/sample - loss: 0.0987 - val_loss: 0.0883\n",
      "Epoch 105/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0969 - val_loss: 0.0887\n",
      "Epoch 106/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0955 - val_loss: 0.0859\n",
      "Epoch 107/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0966 - val_loss: 0.0857\n",
      "Epoch 108/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0928 - val_loss: 0.0837\n",
      "Epoch 109/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0915 - val_loss: 0.0822\n",
      "Epoch 110/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0901 - val_loss: 0.0805\n",
      "Epoch 111/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0890 - val_loss: 0.0794\n",
      "Epoch 112/600\n",
      "1029/1029 [==============================] - 0s 72us/sample - loss: 0.0878 - val_loss: 0.0784\n",
      "Epoch 113/600\n",
      "1029/1029 [==============================] - 0s 65us/sample - loss: 0.0867 - val_loss: 0.0779\n",
      "Epoch 114/600\n",
      "1029/1029 [==============================] - 0s 71us/sample - loss: 0.0856 - val_loss: 0.0758\n",
      "Epoch 115/600\n",
      "1029/1029 [==============================] - 0s 87us/sample - loss: 0.0845 - val_loss: 0.0746\n",
      "Epoch 116/600\n",
      "1029/1029 [==============================] - 0s 99us/sample - loss: 0.0832 - val_loss: 0.0740\n",
      "Epoch 117/600\n",
      "1029/1029 [==============================] - 0s 87us/sample - loss: 0.0825 - val_loss: 0.0724\n",
      "Epoch 118/600\n",
      "1029/1029 [==============================] - 0s 84us/sample - loss: 0.0814 - val_loss: 0.0711\n",
      "Epoch 119/600\n",
      "1029/1029 [==============================] - 0s 76us/sample - loss: 0.0803 - val_loss: 0.0718\n",
      "Epoch 120/600\n",
      "1029/1029 [==============================] - 0s 66us/sample - loss: 0.0789 - val_loss: 0.0694\n",
      "Epoch 121/600\n",
      "1029/1029 [==============================] - 0s 65us/sample - loss: 0.0784 - val_loss: 0.0701\n",
      "Epoch 122/600\n",
      "1029/1029 [==============================] - 0s 64us/sample - loss: 0.0775 - val_loss: 0.0670\n",
      "Epoch 123/600\n",
      "1029/1029 [==============================] - 0s 63us/sample - loss: 0.0760 - val_loss: 0.0665\n",
      "Epoch 124/600\n",
      "1029/1029 [==============================] - 0s 65us/sample - loss: 0.0752 - val_loss: 0.0653\n",
      "Epoch 125/600\n",
      "1029/1029 [==============================] - 0s 64us/sample - loss: 0.0743 - val_loss: 0.0645\n",
      "Epoch 126/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0742 - val_loss: 0.0641\n",
      "Epoch 127/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0724 - val_loss: 0.0624\n",
      "Epoch 128/600\n",
      "1029/1029 [==============================] - 0s 63us/sample - loss: 0.0717 - val_loss: 0.0619\n",
      "Epoch 129/600\n",
      "1029/1029 [==============================] - 0s 71us/sample - loss: 0.0708 - val_loss: 0.0619\n",
      "Epoch 130/600\n",
      "1029/1029 [==============================] - 0s 72us/sample - loss: 0.0699 - val_loss: 0.0603\n",
      "Epoch 131/600\n",
      "1029/1029 [==============================] - 0s 62us/sample - loss: 0.0690 - val_loss: 0.0596\n",
      "Epoch 132/600\n",
      "1029/1029 [==============================] - 0s 62us/sample - loss: 0.0683 - val_loss: 0.0582\n",
      "Epoch 133/600\n",
      "1029/1029 [==============================] - 0s 63us/sample - loss: 0.0677 - val_loss: 0.0578\n",
      "Epoch 134/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0667 - val_loss: 0.0573\n",
      "Epoch 135/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0661 - val_loss: 0.0563\n",
      "Epoch 136/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0652 - val_loss: 0.0562\n",
      "Epoch 137/600\n",
      "1029/1029 [==============================] - 0s 62us/sample - loss: 0.0646 - val_loss: 0.0551\n",
      "Epoch 138/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0640 - val_loss: 0.0537\n",
      "Epoch 139/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0635 - val_loss: 0.0536\n",
      "Epoch 140/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0623 - val_loss: 0.0528\n",
      "Epoch 141/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0619 - val_loss: 0.0523\n",
      "Epoch 142/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0610 - val_loss: 0.0519\n",
      "Epoch 143/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0605 - val_loss: 0.0506\n",
      "Epoch 144/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0607 - val_loss: 0.0501\n",
      "Epoch 145/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0591 - val_loss: 0.0499\n",
      "Epoch 146/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0586 - val_loss: 0.0486\n",
      "Epoch 147/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0579 - val_loss: 0.0482\n",
      "Epoch 148/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0573 - val_loss: 0.0480\n",
      "Epoch 149/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0568 - val_loss: 0.0471\n",
      "Epoch 150/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0562 - val_loss: 0.0464\n",
      "Epoch 151/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0557 - val_loss: 0.0458\n",
      "Epoch 152/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0548 - val_loss: 0.0457\n",
      "Epoch 153/600\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0544 - val_loss: 0.0447\n",
      "Epoch 154/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0538 - val_loss: 0.0445\n",
      "Epoch 155/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0536 - val_loss: 0.0435\n",
      "Epoch 156/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0530 - val_loss: 0.0431\n",
      "Epoch 157/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0524 - val_loss: 0.0427\n",
      "Epoch 158/600\n",
      "1029/1029 [==============================] - 0s 62us/sample - loss: 0.0518 - val_loss: 0.0422\n",
      "Epoch 159/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0512 - val_loss: 0.0415\n",
      "Epoch 160/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0513 - val_loss: 0.0414\n",
      "Epoch 161/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0501 - val_loss: 0.0408\n",
      "Epoch 162/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0501 - val_loss: 0.0402\n",
      "Epoch 163/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0491 - val_loss: 0.0396\n",
      "Epoch 164/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0487 - val_loss: 0.0398\n",
      "Epoch 165/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0483 - val_loss: 0.0389\n",
      "Epoch 166/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0480 - val_loss: 0.0389\n",
      "Epoch 167/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0476 - val_loss: 0.0380\n",
      "Epoch 168/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0470 - val_loss: 0.0378\n",
      "Epoch 169/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0464 - val_loss: 0.0373\n",
      "Epoch 170/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0461 - val_loss: 0.0369\n",
      "Epoch 171/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0455 - val_loss: 0.0364\n",
      "Epoch 172/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0450 - val_loss: 0.0360\n",
      "Epoch 173/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0447 - val_loss: 0.0357\n",
      "Epoch 174/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0449 - val_loss: 0.0351\n",
      "Epoch 175/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0439 - val_loss: 0.0349\n",
      "Epoch 176/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0435 - val_loss: 0.0344\n",
      "Epoch 177/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0431 - val_loss: 0.0340\n",
      "Epoch 178/600\n",
      "1029/1029 [==============================] - 0s 75us/sample - loss: 0.0432 - val_loss: 0.0340\n",
      "Epoch 179/600\n",
      "1029/1029 [==============================] - 0s 68us/sample - loss: 0.0427 - val_loss: 0.0331\n",
      "Epoch 180/600\n",
      "1029/1029 [==============================] - 0s 66us/sample - loss: 0.0419 - val_loss: 0.0329\n",
      "Epoch 181/600\n",
      "1029/1029 [==============================] - 0s 69us/sample - loss: 0.0416 - val_loss: 0.0327\n",
      "Epoch 182/600\n",
      "1029/1029 [==============================] - 0s 80us/sample - loss: 0.0411 - val_loss: 0.0324\n",
      "Epoch 183/600\n",
      "1029/1029 [==============================] - 0s 66us/sample - loss: 0.0408 - val_loss: 0.0320\n",
      "Epoch 184/600\n",
      "1029/1029 [==============================] - 0s 63us/sample - loss: 0.0407 - val_loss: 0.0318\n",
      "Epoch 185/600\n",
      "1029/1029 [==============================] - 0s 72us/sample - loss: 0.0401 - val_loss: 0.0312\n",
      "Epoch 186/600\n",
      "1029/1029 [==============================] - 0s 84us/sample - loss: 0.0400 - val_loss: 0.0311\n",
      "Epoch 187/600\n",
      "1029/1029 [==============================] - 0s 100us/sample - loss: 0.0395 - val_loss: 0.0306\n",
      "Epoch 188/600\n",
      "1029/1029 [==============================] - 0s 112us/sample - loss: 0.0388 - val_loss: 0.0300\n",
      "Epoch 189/600\n",
      "1029/1029 [==============================] - 0s 73us/sample - loss: 0.0384 - val_loss: 0.0300\n",
      "Epoch 190/600\n",
      "1029/1029 [==============================] - 0s 71us/sample - loss: 0.0381 - val_loss: 0.0293\n",
      "Epoch 191/600\n",
      "1029/1029 [==============================] - 0s 73us/sample - loss: 0.0378 - val_loss: 0.0294\n",
      "Epoch 192/600\n",
      "1029/1029 [==============================] - 0s 66us/sample - loss: 0.0375 - val_loss: 0.0290\n",
      "Epoch 193/600\n",
      "1029/1029 [==============================] - 0s 90us/sample - loss: 0.0371 - val_loss: 0.0285\n",
      "Epoch 194/600\n",
      "1029/1029 [==============================] - 0s 97us/sample - loss: 0.0366 - val_loss: 0.0284\n",
      "Epoch 195/600\n",
      "1029/1029 [==============================] - 0s 87us/sample - loss: 0.0371 - val_loss: 0.0278\n",
      "Epoch 196/600\n",
      "1029/1029 [==============================] - 0s 104us/sample - loss: 0.0365 - val_loss: 0.0276\n",
      "Epoch 197/600\n",
      "1029/1029 [==============================] - 0s 82us/sample - loss: 0.0358 - val_loss: 0.0273\n",
      "Epoch 198/600\n",
      "1029/1029 [==============================] - 0s 63us/sample - loss: 0.0357 - val_loss: 0.0270\n",
      "Epoch 199/600\n",
      "1029/1029 [==============================] - 0s 64us/sample - loss: 0.0352 - val_loss: 0.0267\n",
      "Epoch 200/600\n",
      "1029/1029 [==============================] - 0s 67us/sample - loss: 0.0349 - val_loss: 0.0266\n",
      "Epoch 201/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0348 - val_loss: 0.0261\n",
      "Epoch 202/600\n",
      "1029/1029 [==============================] - 0s 62us/sample - loss: 0.0343 - val_loss: 0.0262\n",
      "Epoch 203/600\n",
      "1029/1029 [==============================] - 0s 63us/sample - loss: 0.0341 - val_loss: 0.0256\n",
      "Epoch 204/600\n",
      "1029/1029 [==============================] - 0s 70us/sample - loss: 0.0338 - val_loss: 0.0255\n",
      "Epoch 205/600\n",
      "1029/1029 [==============================] - 0s 73us/sample - loss: 0.0334 - val_loss: 0.0251\n",
      "Epoch 206/600\n",
      "1029/1029 [==============================] - 0s 74us/sample - loss: 0.0328 - val_loss: 0.0251\n",
      "Epoch 207/600\n",
      "1029/1029 [==============================] - 0s 76us/sample - loss: 0.0327 - val_loss: 0.0249\n",
      "Epoch 208/600\n",
      "1029/1029 [==============================] - 0s 77us/sample - loss: 0.0324 - val_loss: 0.0244\n",
      "Epoch 209/600\n",
      "1029/1029 [==============================] - 0s 72us/sample - loss: 0.0326 - val_loss: 0.0242\n",
      "Epoch 210/600\n",
      "1029/1029 [==============================] - 0s 72us/sample - loss: 0.0319 - val_loss: 0.0239\n",
      "Epoch 211/600\n",
      "1029/1029 [==============================] - 0s 66us/sample - loss: 0.0316 - val_loss: 0.0237\n",
      "Epoch 212/600\n",
      "1029/1029 [==============================] - 0s 66us/sample - loss: 0.0312 - val_loss: 0.0234\n",
      "Epoch 213/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0311 - val_loss: 0.0234\n",
      "Epoch 214/600\n",
      "1029/1029 [==============================] - 0s 62us/sample - loss: 0.0309 - val_loss: 0.0232\n",
      "Epoch 215/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0306 - val_loss: 0.0227\n",
      "Epoch 216/600\n",
      "1029/1029 [==============================] - 0s 62us/sample - loss: 0.0308 - val_loss: 0.0226\n",
      "Epoch 217/600\n",
      "1029/1029 [==============================] - 0s 62us/sample - loss: 0.0305 - val_loss: 0.0223\n",
      "Epoch 218/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0299 - val_loss: 0.0226\n",
      "Epoch 219/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0295 - val_loss: 0.0219\n",
      "Epoch 220/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0294 - val_loss: 0.0219\n",
      "Epoch 221/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0291 - val_loss: 0.0218\n",
      "Epoch 222/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0287 - val_loss: 0.0213\n",
      "Epoch 223/600\n",
      "1029/1029 [==============================] - 0s 91us/sample - loss: 0.0285 - val_loss: 0.0213\n",
      "Epoch 224/600\n",
      "1029/1029 [==============================] - 0s 74us/sample - loss: 0.0281 - val_loss: 0.0209\n",
      "Epoch 225/600\n",
      "1029/1029 [==============================] - 0s 69us/sample - loss: 0.0281 - val_loss: 0.0207\n",
      "Epoch 226/600\n",
      "1029/1029 [==============================] - 0s 65us/sample - loss: 0.0277 - val_loss: 0.0206\n",
      "Epoch 227/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0277 - val_loss: 0.0203\n",
      "Epoch 228/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0278 - val_loss: 0.0202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0272 - val_loss: 0.0200\n",
      "Epoch 230/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0270 - val_loss: 0.0199\n",
      "Epoch 231/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0267 - val_loss: 0.0197\n",
      "Epoch 232/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0264 - val_loss: 0.0194\n",
      "Epoch 233/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0261 - val_loss: 0.0192\n",
      "Epoch 234/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0259 - val_loss: 0.0190\n",
      "Epoch 235/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0259 - val_loss: 0.0188\n",
      "Epoch 236/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0256 - val_loss: 0.0186\n",
      "Epoch 237/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0254 - val_loss: 0.0184\n",
      "Epoch 238/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0251 - val_loss: 0.0183\n",
      "Epoch 239/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0249 - val_loss: 0.0182\n",
      "Epoch 240/600\n",
      "1029/1029 [==============================] - 0s 72us/sample - loss: 0.0248 - val_loss: 0.0179\n",
      "Epoch 241/600\n",
      "1029/1029 [==============================] - 0s 71us/sample - loss: 0.0247 - val_loss: 0.0179\n",
      "Epoch 242/600\n",
      "1029/1029 [==============================] - 0s 69us/sample - loss: 0.0244 - val_loss: 0.0176\n",
      "Epoch 243/600\n",
      "1029/1029 [==============================] - 0s 62us/sample - loss: 0.0240 - val_loss: 0.0174\n",
      "Epoch 244/600\n",
      "1029/1029 [==============================] - 0s 63us/sample - loss: 0.0240 - val_loss: 0.0173\n",
      "Epoch 245/600\n",
      "1029/1029 [==============================] - 0s 66us/sample - loss: 0.0237 - val_loss: 0.0171\n",
      "Epoch 246/600\n",
      "1029/1029 [==============================] - 0s 66us/sample - loss: 0.0236 - val_loss: 0.0171\n",
      "Epoch 247/600\n",
      "1029/1029 [==============================] - 0s 66us/sample - loss: 0.0233 - val_loss: 0.0168\n",
      "Epoch 248/600\n",
      "1029/1029 [==============================] - 0s 65us/sample - loss: 0.0231 - val_loss: 0.0166\n",
      "Epoch 249/600\n",
      "1029/1029 [==============================] - 0s 65us/sample - loss: 0.0229 - val_loss: 0.0166\n",
      "Epoch 250/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0229 - val_loss: 0.0163\n",
      "Epoch 251/600\n",
      "1029/1029 [==============================] - 0s 63us/sample - loss: 0.0229 - val_loss: 0.0161\n",
      "Epoch 252/600\n",
      "1029/1029 [==============================] - 0s 62us/sample - loss: 0.0224 - val_loss: 0.0161\n",
      "Epoch 253/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0224 - val_loss: 0.0159\n",
      "Epoch 254/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0220 - val_loss: 0.0158\n",
      "Epoch 255/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0219 - val_loss: 0.0156\n",
      "Epoch 256/600\n",
      "1029/1029 [==============================] - 0s 66us/sample - loss: 0.0215 - val_loss: 0.0155\n",
      "Epoch 257/600\n",
      "1029/1029 [==============================] - 0s 63us/sample - loss: 0.0217 - val_loss: 0.0153\n",
      "Epoch 258/600\n",
      "1029/1029 [==============================] - 0s 66us/sample - loss: 0.0212 - val_loss: 0.0154\n",
      "Epoch 259/600\n",
      "1029/1029 [==============================] - 0s 64us/sample - loss: 0.0213 - val_loss: 0.0150\n",
      "Epoch 260/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0209 - val_loss: 0.0150\n",
      "Epoch 261/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0207 - val_loss: 0.0148\n",
      "Epoch 262/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0206 - val_loss: 0.0146\n",
      "Epoch 263/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0205 - val_loss: 0.0145\n",
      "Epoch 264/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0203 - val_loss: 0.0145\n",
      "Epoch 265/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0206 - val_loss: 0.0143\n",
      "Epoch 266/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0199 - val_loss: 0.0143\n",
      "Epoch 267/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0198 - val_loss: 0.0140\n",
      "Epoch 268/600\n",
      "1029/1029 [==============================] - 0s 63us/sample - loss: 0.0199 - val_loss: 0.0140\n",
      "Epoch 269/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0195 - val_loss: 0.0138\n",
      "Epoch 270/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0195 - val_loss: 0.0137\n",
      "Epoch 271/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0191 - val_loss: 0.0135\n",
      "Epoch 272/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0190 - val_loss: 0.0134\n",
      "Epoch 273/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0188 - val_loss: 0.0133\n",
      "Epoch 274/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0188 - val_loss: 0.0133\n",
      "Epoch 275/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0185 - val_loss: 0.0131\n",
      "Epoch 276/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0184 - val_loss: 0.0130\n",
      "Epoch 277/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0184 - val_loss: 0.0130\n",
      "Epoch 278/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0181 - val_loss: 0.0128\n",
      "Epoch 279/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0183 - val_loss: 0.0127\n",
      "Epoch 280/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0181 - val_loss: 0.0125\n",
      "Epoch 281/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0177 - val_loss: 0.0124\n",
      "Epoch 282/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0178 - val_loss: 0.0123\n",
      "Epoch 283/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0176 - val_loss: 0.0123\n",
      "Epoch 284/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0175 - val_loss: 0.0122\n",
      "Epoch 285/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0174 - val_loss: 0.0121\n",
      "Epoch 286/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0173 - val_loss: 0.0119\n",
      "Epoch 287/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0185 - val_loss: 0.0119\n",
      "Epoch 288/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0171 - val_loss: 0.0117\n",
      "Epoch 289/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0167 - val_loss: 0.0118\n",
      "Epoch 290/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0169 - val_loss: 0.0117\n",
      "Epoch 291/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0165 - val_loss: 0.0114\n",
      "Epoch 292/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0166 - val_loss: 0.0113\n",
      "Epoch 293/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0170 - val_loss: 0.0113\n",
      "Epoch 294/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0160 - val_loss: 0.0112\n",
      "Epoch 295/600\n",
      "1029/1029 [==============================] - 0s 62us/sample - loss: 0.0160 - val_loss: 0.0112\n",
      "Epoch 296/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0159 - val_loss: 0.0110\n",
      "Epoch 297/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0158 - val_loss: 0.0109\n",
      "Epoch 298/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0156 - val_loss: 0.0108\n",
      "Epoch 299/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0155 - val_loss: 0.0107\n",
      "Epoch 300/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0155 - val_loss: 0.0106\n",
      "Epoch 301/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0153 - val_loss: 0.0105\n",
      "Epoch 302/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0152 - val_loss: 0.0105\n",
      "Epoch 303/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0151 - val_loss: 0.0104\n",
      "Epoch 304/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0152 - val_loss: 0.0103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 305/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0149 - val_loss: 0.0104\n",
      "Epoch 306/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0148 - val_loss: 0.0101\n",
      "Epoch 307/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0146 - val_loss: 0.0100\n",
      "Epoch 308/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0146 - val_loss: 0.0100\n",
      "Epoch 309/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0145 - val_loss: 0.0100\n",
      "Epoch 310/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0145 - val_loss: 0.0098\n",
      "Epoch 311/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0143 - val_loss: 0.0098\n",
      "Epoch 312/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0141 - val_loss: 0.0096\n",
      "Epoch 313/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0139 - val_loss: 0.0095\n",
      "Epoch 314/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0141 - val_loss: 0.0095\n",
      "Epoch 315/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0138 - val_loss: 0.0095\n",
      "Epoch 316/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0137 - val_loss: 0.0093\n",
      "Epoch 317/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0136 - val_loss: 0.0093\n",
      "Epoch 318/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0135 - val_loss: 0.0092\n",
      "Epoch 319/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0134 - val_loss: 0.0091\n",
      "Epoch 320/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0134 - val_loss: 0.0091\n",
      "Epoch 321/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0132 - val_loss: 0.0089\n",
      "Epoch 322/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0132 - val_loss: 0.0089\n",
      "Epoch 323/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0133 - val_loss: 0.0091\n",
      "Epoch 324/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0128 - val_loss: 0.0087\n",
      "Epoch 325/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0129 - val_loss: 0.0087\n",
      "Epoch 326/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0131 - val_loss: 0.0086\n",
      "Epoch 327/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0129 - val_loss: 0.0085\n",
      "Epoch 328/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0126 - val_loss: 0.0084\n",
      "Epoch 329/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0125 - val_loss: 0.0084\n",
      "Epoch 330/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0125 - val_loss: 0.0083\n",
      "Epoch 331/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0123 - val_loss: 0.0082\n",
      "Epoch 332/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0121 - val_loss: 0.0083\n",
      "Epoch 333/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0121 - val_loss: 0.0081\n",
      "Epoch 334/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0121 - val_loss: 0.0081\n",
      "Epoch 335/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0119 - val_loss: 0.0080\n",
      "Epoch 336/600\n",
      "1029/1029 [==============================] - 0s 66us/sample - loss: 0.0118 - val_loss: 0.0080\n",
      "Epoch 337/600\n",
      "1029/1029 [==============================] - 0s 71us/sample - loss: 0.0120 - val_loss: 0.0079\n",
      "Epoch 338/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0118 - val_loss: 0.0080\n",
      "Epoch 339/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0117 - val_loss: 0.0078\n",
      "Epoch 340/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0116 - val_loss: 0.0078\n",
      "Epoch 341/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0115 - val_loss: 0.0076\n",
      "Epoch 342/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0116 - val_loss: 0.0076\n",
      "Epoch 343/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0115 - val_loss: 0.0076\n",
      "Epoch 344/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0111 - val_loss: 0.0075\n",
      "Epoch 345/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0112 - val_loss: 0.0075\n",
      "Epoch 346/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0112 - val_loss: 0.0073\n",
      "Epoch 347/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0115 - val_loss: 0.0073\n",
      "Epoch 348/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 349/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0109 - val_loss: 0.0072\n",
      "Epoch 350/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0110 - val_loss: 0.0074\n",
      "Epoch 351/600\n",
      "1029/1029 [==============================] - 0s 68us/sample - loss: 0.0110 - val_loss: 0.0070\n",
      "Epoch 352/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0106 - val_loss: 0.0071\n",
      "Epoch 353/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0105 - val_loss: 0.0072\n",
      "Epoch 354/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0107 - val_loss: 0.0069\n",
      "Epoch 355/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0103 - val_loss: 0.0072\n",
      "Epoch 356/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0104 - val_loss: 0.0068\n",
      "Epoch 357/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0102 - val_loss: 0.0067\n",
      "Epoch 358/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0101 - val_loss: 0.0067\n",
      "Epoch 359/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0100 - val_loss: 0.0067\n",
      "Epoch 360/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0102 - val_loss: 0.0068\n",
      "Epoch 361/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0101 - val_loss: 0.0066\n",
      "Epoch 362/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0102 - val_loss: 0.0066\n",
      "Epoch 363/600\n",
      "1029/1029 [==============================] - 0s 62us/sample - loss: 0.0099 - val_loss: 0.0066\n",
      "Epoch 364/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0098 - val_loss: 0.0066\n",
      "Epoch 365/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0100 - val_loss: 0.0065\n",
      "Epoch 366/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0099 - val_loss: 0.0064\n",
      "Epoch 367/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0095 - val_loss: 0.0065\n",
      "Epoch 368/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0095 - val_loss: 0.0063\n",
      "Epoch 369/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0094 - val_loss: 0.0063\n",
      "Epoch 370/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0093 - val_loss: 0.0063\n",
      "Epoch 371/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0092 - val_loss: 0.0061\n",
      "Epoch 372/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0092 - val_loss: 0.0061\n",
      "Epoch 373/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0090 - val_loss: 0.0061\n",
      "Epoch 374/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0103 - val_loss: 0.0061\n",
      "Epoch 375/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0091 - val_loss: 0.0059\n",
      "Epoch 376/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0087 - val_loss: 0.0059\n",
      "Epoch 377/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0090 - val_loss: 0.0060\n",
      "Epoch 378/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0089 - val_loss: 0.0059\n",
      "Epoch 379/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0085 - val_loss: 0.0059\n",
      "Epoch 380/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0087 - val_loss: 0.0059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 381/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0084 - val_loss: 0.0058\n",
      "Epoch 382/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0085 - val_loss: 0.0058\n",
      "Epoch 383/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0085 - val_loss: 0.0057\n",
      "Epoch 384/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0084 - val_loss: 0.0057\n",
      "Epoch 385/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0084 - val_loss: 0.0059\n",
      "Epoch 386/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0083 - val_loss: 0.0057\n",
      "Epoch 387/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0083 - val_loss: 0.0056\n",
      "Epoch 388/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0082 - val_loss: 0.0056\n",
      "Epoch 389/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0083 - val_loss: 0.0055\n",
      "Epoch 390/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0081 - val_loss: 0.0055\n",
      "Epoch 391/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0079 - val_loss: 0.0055\n",
      "Epoch 392/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0078 - val_loss: 0.0056\n",
      "Epoch 393/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0078 - val_loss: 0.0054\n",
      "Epoch 394/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0077 - val_loss: 0.0055\n",
      "Epoch 395/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0077 - val_loss: 0.0054\n",
      "Epoch 396/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0077 - val_loss: 0.0054\n",
      "Epoch 397/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0077 - val_loss: 0.0053\n",
      "Epoch 398/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0079 - val_loss: 0.0054\n",
      "Epoch 399/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0078 - val_loss: 0.0053\n",
      "Epoch 400/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0074 - val_loss: 0.0053\n",
      "Epoch 401/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0074 - val_loss: 0.0053\n",
      "Epoch 402/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0074 - val_loss: 0.0052\n",
      "Epoch 403/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 404/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0073 - val_loss: 0.0053\n",
      "Epoch 405/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0079 - val_loss: 0.0056\n",
      "Epoch 406/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0075 - val_loss: 0.0051\n",
      "Epoch 407/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 408/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 409/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0073 - val_loss: 0.0049\n",
      "Epoch 410/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0071 - val_loss: 0.0051\n",
      "Epoch 411/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0071 - val_loss: 0.0052\n",
      "Epoch 412/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0071 - val_loss: 0.0049\n",
      "Epoch 413/600\n",
      "1029/1029 [==============================] - 0s 63us/sample - loss: 0.0070 - val_loss: 0.0049\n",
      "Epoch 414/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0067 - val_loss: 0.0048\n",
      "Epoch 415/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0069 - val_loss: 0.0049\n",
      "Epoch 416/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0068 - val_loss: 0.0047\n",
      "Epoch 417/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0068 - val_loss: 0.0047\n",
      "Epoch 418/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0070 - val_loss: 0.0047\n",
      "Epoch 419/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0067 - val_loss: 0.0046\n",
      "Epoch 420/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0067 - val_loss: 0.0047\n",
      "Epoch 421/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0068 - val_loss: 0.0047\n",
      "Epoch 422/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0068 - val_loss: 0.0046\n",
      "Epoch 423/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0063 - val_loss: 0.0045\n",
      "Epoch 424/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0066 - val_loss: 0.0045\n",
      "Epoch 425/600\n",
      "1029/1029 [==============================] - 0s 79us/sample - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 426/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 427/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0064 - val_loss: 0.0045\n",
      "Epoch 428/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0064 - val_loss: 0.0046\n",
      "Epoch 429/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0062 - val_loss: 0.0044\n",
      "Epoch 430/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 431/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0061 - val_loss: 0.0044\n",
      "Epoch 432/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0079 - val_loss: 0.0045\n",
      "Epoch 433/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0065 - val_loss: 0.0042\n",
      "Epoch 434/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0061 - val_loss: 0.0042\n",
      "Epoch 435/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0059 - val_loss: 0.0042\n",
      "Epoch 436/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 437/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0058 - val_loss: 0.0042\n",
      "Epoch 438/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0060 - val_loss: 0.0041\n",
      "Epoch 439/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0059 - val_loss: 0.0043\n",
      "Epoch 440/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0060 - val_loss: 0.0042\n",
      "Epoch 441/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0058 - val_loss: 0.0041\n",
      "Epoch 442/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0057 - val_loss: 0.0041\n",
      "Epoch 443/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 444/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 445/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 446/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0057 - val_loss: 0.0040\n",
      "Epoch 447/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0056 - val_loss: 0.0040\n",
      "Epoch 448/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0056 - val_loss: 0.0041\n",
      "Epoch 449/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0055 - val_loss: 0.0040\n",
      "Epoch 450/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 451/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0054 - val_loss: 0.0039\n",
      "Epoch 452/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 453/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0055 - val_loss: 0.0039\n",
      "Epoch 454/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 455/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0054 - val_loss: 0.0038\n",
      "Epoch 456/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0053 - val_loss: 0.0042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 457/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0056 - val_loss: 0.0039\n",
      "Epoch 458/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0053 - val_loss: 0.0039\n",
      "Epoch 459/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0053 - val_loss: 0.0037\n",
      "Epoch 460/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0054 - val_loss: 0.0037\n",
      "Epoch 461/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 462/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0052 - val_loss: 0.0037\n",
      "Epoch 463/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 464/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0052 - val_loss: 0.0036\n",
      "Epoch 465/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0051 - val_loss: 0.0037\n",
      "Epoch 466/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0050 - val_loss: 0.0037\n",
      "Epoch 467/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0051 - val_loss: 0.0038\n",
      "Epoch 468/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0051 - val_loss: 0.0035\n",
      "Epoch 469/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0054 - val_loss: 0.0036\n",
      "Epoch 470/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0049 - val_loss: 0.0038\n",
      "Epoch 471/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0048 - val_loss: 0.0035\n",
      "Epoch 472/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 473/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0047 - val_loss: 0.0031\n",
      "Epoch 474/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0050 - val_loss: 0.0030\n",
      "Epoch 475/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0055 - val_loss: 0.0030\n",
      "Epoch 476/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 477/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0046 - val_loss: 0.0033\n",
      "Epoch 478/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0045 - val_loss: 0.0029\n",
      "Epoch 479/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0043 - val_loss: 0.0031\n",
      "Epoch 480/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0044 - val_loss: 0.0028\n",
      "Epoch 481/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0045 - val_loss: 0.0031\n",
      "Epoch 482/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0042 - val_loss: 0.0028\n",
      "Epoch 483/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0042 - val_loss: 0.0029\n",
      "Epoch 484/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0043 - val_loss: 0.0029\n",
      "Epoch 485/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0041 - val_loss: 0.0032\n",
      "Epoch 486/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0041 - val_loss: 0.0027\n",
      "Epoch 487/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0041 - val_loss: 0.0029\n",
      "Epoch 488/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0042 - val_loss: 0.0032\n",
      "Epoch 489/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 490/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0039 - val_loss: 0.0029\n",
      "Epoch 491/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0040 - val_loss: 0.0026\n",
      "Epoch 492/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0039 - val_loss: 0.0026\n",
      "Epoch 493/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0039 - val_loss: 0.0028\n",
      "Epoch 494/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 495/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0038 - val_loss: 0.0026\n",
      "Epoch 496/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0039 - val_loss: 0.0027\n",
      "Epoch 497/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0036 - val_loss: 0.0025\n",
      "Epoch 498/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0050 - val_loss: 0.0031\n",
      "Epoch 499/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0039 - val_loss: 0.0025\n",
      "Epoch 500/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 501/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0037 - val_loss: 0.0026\n",
      "Epoch 502/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0046 - val_loss: 0.0028\n",
      "Epoch 503/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0037 - val_loss: 0.0023\n",
      "Epoch 504/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0037 - val_loss: 0.0024\n",
      "Epoch 505/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0038 - val_loss: 0.0024\n",
      "Epoch 506/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 507/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0035 - val_loss: 0.0024\n",
      "Epoch 508/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 509/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 510/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0034 - val_loss: 0.0024\n",
      "Epoch 511/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0035 - val_loss: 0.0023\n",
      "Epoch 512/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0034 - val_loss: 0.0023\n",
      "Epoch 513/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0041 - val_loss: 0.0024\n",
      "Epoch 514/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 515/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 516/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0033 - val_loss: 0.0023\n",
      "Epoch 517/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 518/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 519/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0033 - val_loss: 0.0022\n",
      "Epoch 520/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0033 - val_loss: 0.0024\n",
      "Epoch 521/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0034 - val_loss: 0.0022\n",
      "Epoch 522/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 523/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 524/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0031 - val_loss: 0.0022\n",
      "Epoch 525/600\n",
      "1029/1029 [==============================] - 0s 64us/sample - loss: 0.0032 - val_loss: 0.0022\n",
      "Epoch 526/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0032 - val_loss: 0.0021\n",
      "Epoch 527/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0031 - val_loss: 0.0023\n",
      "Epoch 528/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0033 - val_loss: 0.0021\n",
      "Epoch 529/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 530/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 531/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 532/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0030 - val_loss: 0.0021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 533/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0031 - val_loss: 0.0021\n",
      "Epoch 534/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 535/600\n",
      "1029/1029 [==============================] - 0s 147us/sample - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 536/600\n",
      "1029/1029 [==============================] - 0s 200us/sample - loss: 0.0030 - val_loss: 0.0021\n",
      "Epoch 537/600\n",
      "1029/1029 [==============================] - 0s 75us/sample - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 538/600\n",
      "1029/1029 [==============================] - 0s 65us/sample - loss: 0.0030 - val_loss: 0.0020\n",
      "Epoch 539/600\n",
      "1029/1029 [==============================] - 0s 64us/sample - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 540/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 541/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0032 - val_loss: 0.0019\n",
      "Epoch 542/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 543/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0029 - val_loss: 0.0020\n",
      "Epoch 544/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 545/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0029 - val_loss: 0.0019\n",
      "Epoch 546/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0029 - val_loss: 0.0022\n",
      "Epoch 547/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0029 - val_loss: 0.0021\n",
      "Epoch 548/600\n",
      "1029/1029 [==============================] - 0s 82us/sample - loss: 0.0028 - val_loss: 0.0019\n",
      "Epoch 549/600\n",
      "1029/1029 [==============================] - 0s 86us/sample - loss: 0.0028 - val_loss: 0.0018\n",
      "Epoch 550/600\n",
      "1029/1029 [==============================] - 0s 72us/sample - loss: 0.0028 - val_loss: 0.0020\n",
      "Epoch 551/600\n",
      "1029/1029 [==============================] - 0s 74us/sample - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 552/600\n",
      "1029/1029 [==============================] - 0s 74us/sample - loss: 0.0027 - val_loss: 0.0019\n",
      "Epoch 553/600\n",
      "1029/1029 [==============================] - 0s 65us/sample - loss: 0.0028 - val_loss: 0.0021\n",
      "Epoch 554/600\n",
      "1029/1029 [==============================] - 0s 63us/sample - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 555/600\n",
      "1029/1029 [==============================] - 0s 64us/sample - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 556/600\n",
      "1029/1029 [==============================] - 0s 64us/sample - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 557/600\n",
      "1029/1029 [==============================] - 0s 63us/sample - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 558/600\n",
      "1029/1029 [==============================] - 0s 63us/sample - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 559/600\n",
      "1029/1029 [==============================] - 0s 75us/sample - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 560/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0026 - val_loss: 0.0019\n",
      "Epoch 561/600\n",
      "1029/1029 [==============================] - 0s 63us/sample - loss: 0.0027 - val_loss: 0.0018\n",
      "Epoch 562/600\n",
      "1029/1029 [==============================] - 0s 60us/sample - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 563/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 564/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0025 - val_loss: 0.0018\n",
      "Epoch 565/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0026 - val_loss: 0.0018\n",
      "Epoch 566/600\n",
      "1029/1029 [==============================] - 0s 62us/sample - loss: 0.0026 - val_loss: 0.0017\n",
      "Epoch 567/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 568/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 569/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 570/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 571/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 572/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0025 - val_loss: 0.0017\n",
      "Epoch 573/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0024 - val_loss: 0.0018\n",
      "Epoch 574/600\n",
      "1029/1029 [==============================] - 0s 57us/sample - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 575/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0025 - val_loss: 0.0021\n",
      "Epoch 576/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 577/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 578/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 579/600\n",
      "1029/1029 [==============================] - 0s 59us/sample - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 580/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 581/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 582/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0024 - val_loss: 0.0017\n",
      "Epoch 583/600\n",
      "1029/1029 [==============================] - 0s 61us/sample - loss: 0.0023 - val_loss: 0.0015\n",
      "Epoch 584/600\n",
      "1029/1029 [==============================] - 0s 63us/sample - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 585/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0022 - val_loss: 0.0015\n",
      "Epoch 586/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 587/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0023 - val_loss: 0.0017\n",
      "Epoch 588/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0024 - val_loss: 0.0016\n",
      "Epoch 589/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0023 - val_loss: 0.0016\n",
      "Epoch 590/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0023 - val_loss: 0.0018\n",
      "Epoch 591/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 592/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0022 - val_loss: 0.0014\n",
      "Epoch 593/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0023 - val_loss: 0.0014\n",
      "Epoch 594/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 595/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0021 - val_loss: 0.0014\n",
      "Epoch 596/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0022 - val_loss: 0.0016\n",
      "Epoch 597/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0021 - val_loss: 0.0015\n",
      "Epoch 598/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 599/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0020 - val_loss: 0.0014\n",
      "Epoch 600/600\n",
      "1029/1029 [==============================] - 0s 58us/sample - loss: 0.0022 - val_loss: 0.0014\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7fa1ff456ed0>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X_train,y=y_train, epochs=600,validation_data=(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f29c9f3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss = pd.DataFrame(model.history.history)\n",
    "loss.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2b6fa72",
   "metadata": {},
   "source": [
    "Our model did very well during training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ba1daa",
   "metadata": {},
   "source": [
    "### Model Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ea180d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict_classes(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "d80f7a6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[200   0]\n",
      " [  0 143]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "ab609ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       200\n",
      "           1       1.00      1.00      1.00       143\n",
      "\n",
      "    accuracy                           1.00       343\n",
      "   macro avg       1.00      1.00      1.00       343\n",
      "weighted avg       1.00      1.00      1.00       343\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predictions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ceeb42",
   "metadata": {},
   "source": [
    "The model performed very well on the test dataset, achieving an accuracy of 99%. Further improvements\n",
    "could possibly be made by tuning hyperparameters to figure out the optimal model structure. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
